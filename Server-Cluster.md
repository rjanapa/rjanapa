<b>A Clustered Server environment help businesses save money</b><br>
  
Almost all businesses rely on online services for critical business processes.

Downtime and performance disruptions represent lost productivity and sales, along with mitigation, reputation, and other costs.

The real cost of tech glitches and outdated technology could mean millions.

For this reason, a large and growing number of businesses make a modest investment in upgrading their infrastructure to an architecture based on server clusters.

<b>What is a Server Cluster?</b><br>

<b>A server cluster is a unified group of servers, distributed and managed under a single IP address</b>, which serves as a single entity to ensure higher availability, 
proper load balancing, and system scalability. 

<b>Each server is a node with its own storage (hard drive), memory (RAM), and processing (CPU) resources to command.</b><br>

A two-node cluster, for instance, means that if one server crashes, the second will immediately take over. 
Ideally, multiple web and app nodes are utilized to guarantee hardware redundancy. 
This kind of architecture, known as a high-availability cluster, prevents downtime if component failure hits. 
This is especially true if the OS fails, which does not have redundancy in a single-standing server. Users will not even know that the server crashed.

In addition, there are two usual types of server clusters – manual and automatic.

Manual clusters are not an ideal solution because the manual configuration of a node to a single IP address comes with downtime. 
Even a 2 to 5-minute downtime could be critical for a business, let alone cost money.
On the other hand, when automatic clusters are deployed, an automatic switchover takes place as a result of previously configured software to carry out the switch.

<b>Why are Server Clusters Deployed?</b><br>

Server clusters are often deployed by businesses in order to avoid downtime and maintain system accessibility, even in the event of a critical hardware failure.
For many businesses suffering from performance degradation, splitting off the database server can also enable fast and uninterrupted performance for 
high-volume workloads.
  
<b>1. High Availability (HA) Server Clusters</b><br>

High Availability (HA) clusters are an optimal choice for high traffic websites, such as online shops or applications, to ensure critical systems remain reliable for 
optimal, continuous performance. High availability clusters avoid single points-of-failure, because they are built on redundant hardware and software. 
They are critical for load balancing, system backups and failover, which combine to deliver full-time availability and ensure continuous website operation. 
Comprised of multiple hosts ready to take over when a server shuts down, High Availability clusters guarantee minimal downtime in case of overload or server failure.

High Availability clusters can have two different architectures, either Active – Active or Active – Passive. 
An Active-Active cluster means all nodes work simultaneously to balance loads. 
On the other hand, an Active-Passive architecture means a primary node handles all workload, while a second is waiting to take over in case of downtime. 
When one component crashes, a secondary server, known as a hot spare or hot standby, immediately takes over, 
because the database from the primary server has already been replicated to other nodes. 
This is a lower-cost implementation compared to Active-Active.

High Availability clusters ensure reliability, seamless scalability, more efficient maintenance and robust infrastructure security. 
Not only will users benefit from an enhanced website experience, but High Availability clusters help save costs through reduced downtime.

<b>2. Load Balancing Clusters</b><br>

Load Balancing clusters are a server farm that distributes user requests to multiple active nodes to accelerate operations, ensure redundancy, 
reduce network congestion and overload, and improve workload distribution. Load balancing is a very important use case for server clusters.

Requests are handled by the load balancing software, which directs them to different servers, according to a set of rules or an algorithm, and then handles the 
outgoing response. Load balancing allows for separation of functions and division of workloads between servers to maximize the utilization and availability of 
resources.

High Availability clusters, for example, use a load balancer in an active-active configuration to respond to different requests and then distribute them to all 
independent servers. Workload distribution, in this case, can be either symmetrical or asymmetrical, depending on configurations and computer performance. 
In an active-passive High Availability cluster, the load balancer monitors nodes’ availability, so in case one shuts down, it doesn’t send any more traffic to it until
it is fully operational again.

Load balancing architecture also allows the use of multiple links at the same time, a feature that is very useful in an infrastructure with redundant communication. 
This type of architecture is extensively deployed by telecommunications companies and in datacenters to reduce costs, optimize high-bandwidth data transfers, and
accomplish great scalability and availability.

<b>3. High Performance and Clustered Storage</b><br>

A High-Performance cluster is made up of many computers connected to the same network to perform a task. 
High-Performance clusters are connected to data storage clusters, and together make up a complex architecture that can process data extremely fast. 
Storage and networking components have to keep up with each other for seamless performance and high-speed data transfer.

Also known as supercomputers, High-Performance clusters are not as common as High Availability and Load Balancing clusters, 
but they are used by businesses working with resource-intensive workloads to increase performance, capacity, and reliability. 
They are widely used with IoT (Internet of Things) and AI technology because they facilitate innovation for projects such as live streaming, storm prediction, 
or patient diagnosis, and provide real-time data processing. They are heavily deployed in research labs, for media and entertainment, and in the financial industry, 
among many other industries.

<b>4. Clustered Storage</b><br>

Clustered storage consists of at least two storage servers that scale performance, node space I/O (input/output) and reliability. 
Depending on business requirements and storage demands, clustered storage can be deployed in either a tightly coupled architecture, directed at primary storage and 
with data separated into very small blocks between nodes, or loosely coupled architecture that is self-contained, doesn’t store data across nodes, and delivers more 
flexibility. In a loosely coupled architecture, performance and capacity are limited to the capabilities of the node storing the data. Unlike tightly coupled 
architecture, in this setup scalability with new nodes is not an option.

<b>Why Should a Business Invest in Server Clusters?</b><br>

In the long run, investing in server clusters will save money that can be put to great use somewhere else. A clustered environment will manage hardware failures, as 
well as application and website failures to ensure uptime and availability, saving engineering efforts and potentially drastically reducing the costs associated with 
system recovery.

When functions from network connection to storage all run on an individual server, businesses often deploy a clustered multi-server architecture to significantly 
improve flexibility and scalability. A single server can be scaled to accommodate increasing resource demand, as it is generally simpler for businesses to deploy an 
additional node to an existing cluster, particularly with a managed solution or a managed dedicated server that enables them to do so with a phone call.

Another key motivation driving investment in cluster solutions are availability and fast response. A clustered environment not only ensures hardware redundancy and 
uptime with High Availability clusters, but a cluster with a dedicated database server can have a major impact on website or application speed and performance, while also increasing the number of simultaneous connections supported. Certain regulations, such as PCI-DSS, also require databases containing financial information to be stored on a server which does not directly connect to the internet, making a server cluster a practical necessity for compliance.

To make sure customers can reach a company’s services at all times, the network needs to have built-in redundancy, and the servers need to act as a single system. A 
clustered environment will actually lower IT costs and maintain the server fully operational because they provide continuous uptime. The clustered servers are 
configured to work together on a single network to reduce risk vulnerability and boost network performance.

Businesses of all sizes should consider investing in a clustered server architecture because it will help them better manage processes, from networking services to 
end-user experience and other business workloads. All these workloads are assigned to applications, and they are rolled out on separate servers that communicate with 
each other and stay in sync in real-time. To eliminate single points of failure, a business can have as few as two and as many as hundreds of servers in the clustered 
environment. Each company can benefit from a custom-built infrastructure, specifically engineered for its workload. Look for a reputable service provider that offers 
help from experienced professional to determine the specific architecture that will most cost-effectively deliver the stability and consistency benefits of server 
clusters.

<b>Downtime is Expensive</b><br>

Research firm Gartner announced in 2014 that the average cost of network downtime was $5,600 per minute, resulting in an average hourly cost of more than $300,000. 
More recent global reports from Statista show that in 2017, 24 percent of respondents spent anywhere between $301,000 and 400,000 on one hour of downtime. An unlucky 
14 percent actually ended up spending $5 million or more.

In five of the most expensive and high-profile examples of hefty downtime, Amazon.com lost $220,318.80 per minute, Walmart.com lost $40,771.20 per minute, and Home 
Depot, Best Buy, and Costco all lost more than $10,000 per minute.

If there is one lesson to be learned from these events, it’s that CTOs and CIOs should be concerned about downtime, the cost it will generate for their business, and 
how it will affect their company’s reputation and customer experience. Server clusters are a critical investment any business should consider adding in their budget 
for 2020, if it depends on reliable IT services. A clustered environment will boost performance, and ensure infrastructure availability, scalability, and reliability.

reference: https://www.liquidweb.com/blog/what-is-server-cluster/

Cores and nodes
In this section we will explain what is meant by the terms core and node, and explain why we would want to use multiple cores at once.

<b>What is a core?</b><br>
The term core is used to refer to the Central Processing Unit (CPU) of computing devices.  

Many modern microprocessors include more than one CPUs on the same physical device, these are referred to as multicore. The individual CPUs on the devices are the CPU-cores.  

<b>What is a node?</b><br>

Clusters comprise of a number of servers connected to each other, each of these servers is referred to as a Node. Each node has multiple CPU cores.

Many clusters consist of multiple types of node, these are often used for different types of activity. In many systems there are nodes that are used exclusively for logging into the system and others for computing; these are known as login and compute nodes.

For example, the UCL supercomputer Legion has four node types, these are:

Login nodes<br>
Transfer nodes<br>
Compute nodes<br>
Infrastructure nodes<br>

reference: http://rits.github-pages.ucl.ac.uk/intro-hpchtc/morea/lesson2/reading.html

